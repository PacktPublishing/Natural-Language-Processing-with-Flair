{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 - Embeddings in Flair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook provides a resource to help you follow the code examples from the book more easily. The notebook covers all practical code snippets and exercises found in: Chapter 3 - Embeddings in Flair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The “king - man ≈ queen - woman” analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing and initializing the embedding class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings\n",
    "fasttext = WordEmbeddings('crawl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtaining the embeddings for words A, B and C and computing the embedding D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "\n",
    "def compute_embedding_for_D(A, B, C, embedding):\n",
    "    wordsABC_sentence = Sentence(' '.join([A, B, C]))\n",
    "    embedding.embed(wordsABC_sentence)\n",
    "    \n",
    "    A_embedded = wordsABC_sentence[0].embedding\n",
    "    B_embedded = wordsABC_sentence[1].embedding\n",
    "    C_embedded = wordsABC_sentence[2].embedding\n",
    "    \n",
    "    D_embedding = B_embedded + C_embedded - A_embedded\n",
    "\n",
    "    return D_embedding.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings\n",
    "fasttext = WordEmbeddings('crawl')\n",
    "D = compute_embedding_for_D('king', 'man', 'queen', fasttext)\n",
    "\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtaining embeddings for all English words in Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair import datasets\n",
    "from flair.data import Sentence\n",
    "\n",
    "def get_embedded_english_vocab(embedding):\n",
    "    dataset = datasets.UD_ENGLISH()\n",
    "    vocab_list = dataset.make_vocab_dictionary().get_items()\n",
    "    vocab = Sentence(' '.join(vocab_list))\n",
    "    embedding.embed(vocab)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings\n",
    "fasttext = WordEmbeddings('crawl')\n",
    "\n",
    "print(get_embedded_english_vocab(fasttext)[6].embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the closest matching word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity as sim\n",
    "\n",
    "def find_closest_matching_word(D, vocab, ABC):\n",
    "    max_match = -1\n",
    "    for word in vocab:\n",
    "        match = sim([D], [word.embedding.tolist()])[0][0]\n",
    "        if match > max_match and word.text not in ABC:\n",
    "            max_match = match\n",
    "            closest_matching_word = word.text\n",
    "    return closest_matching_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_is_to_B_as_C_is_to(A, B, C):\n",
    "    fasttext = WordEmbeddings('crawl')\n",
    "    result = compute_embedding_for_D(A, B, C, fasttext)\n",
    "    vocab = get_embedded_english_vocab(fasttext)\n",
    "    D = find_closest_matching_word(result, vocab, {A, B, C})\n",
    "\n",
    "    print(f'{A} is to {B} as {C} is to {D}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting with the analogy solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_is_to_B_as_C_is_to(\"king\", \"man\", \"queen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_is_to_B_as_C_is_to(\"do\", \"did\", \"go\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_is_to_B_as_C_is_to(\"bread\", \"baker\", \"meat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_is_to_B_as_C_is_to(\"London\", \"England\", \"Ljubljana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_is_to_B_as_C_is_to(\"life\", \"death\", \"beginning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_is_to_B_as_C_is_to(\"big\", \"bigger\", \"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_is_to_B_as_C_is_to(\"man\", \"actor\", \"woman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic word embeddings in Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.embeddings import WordEmbeddings\n",
    "\n",
    "embedding = WordEmbeddings('crawl')\n",
    "sentence = Sentence(\"one two three one\")\n",
    "embedding.embed(sentence)\n",
    "\n",
    "for token in sentence:\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token1 = sentence[0]\n",
    "token4 = sentence[3]\n",
    "\n",
    "print(token1.embedding.tolist() == token4.embedding.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flair Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the contextuality of Flair embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.embeddings import FlairEmbeddings\n",
    "\n",
    "embedding = FlairEmbeddings('news-forward')\n",
    "s1 = Sentence(\"nice shirt\")\n",
    "s2 = Sentence(\"nice pants\")\n",
    "\n",
    "embedding.embed(s1)\n",
    "embedding.embed(s2)\n",
    "\n",
    "print(s1[0].embedding.tolist() == s2[0].embedding.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = Sentence(\"very nice shirt\")\n",
    "s2 = Sentence(\"pretty nice pants\")\n",
    "\n",
    "embedding.embed(s1)\n",
    "embedding.embed(s2)\n",
    "\n",
    "print(s1[1].embedding.tolist() == s2[1].embedding.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character level sequence modeling in Flair embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity as sim\n",
    "\n",
    "s1 = Sentence(\"eating potato\")\n",
    "s2 = Sentence(\"eating potatoo\")\n",
    "\n",
    "embedding = FlairEmbeddings('news-forward')\n",
    "embedding.embed(s1)\n",
    "embedding.embed(s2)\n",
    "e1 = s1[1].embedding.tolist()\n",
    "e2 = s2[1].embedding.tolist()\n",
    "\n",
    "print(sim([e1], [e2])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import FlairEmbeddings, WordEmbeddings\n",
    "from flair.embeddings import StackedEmbeddings\n",
    "\n",
    "glove = WordEmbeddings('glove')\n",
    "news_fw = FlairEmbeddings('news-forward')\n",
    "news_bw = FlairEmbeddings('news-backward')\n",
    "\n",
    "combined_embeddings_list = [glove, news_fw, news_bw]\n",
    "\n",
    "stack = StackedEmbeddings(combined_embeddings_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "\n",
    "embedding = TransformerDocumentEmbeddings('bert-base-uncased')\n",
    "\n",
    "sentence = Sentence('Example sentence .')\n",
    "embedding.embed(sentence)\n",
    "\n",
    "print(sentence.embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
